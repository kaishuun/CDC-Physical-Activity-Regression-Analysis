---
title: "STAT 350 - Project"
author: "Kevin He"
date: "11/21/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#loading libraries
library(tidyverse)
library(caret)
library(faraway)
library(usmap)
```


# Abstract
- State something here about the problem
- State something quick procedures (perform regression analysis with these methods)
- Briefly Summarize Conclusion

# Introduction

The Centers for Disease Control and Prevention (CDC) recommends that adults need at minimum 150 minutes of aerobic activity and at least 2 days of muscle-strengthening activities per weeks, but only 1 in 4 adults in the United States (US) and 1 in 5 high school students satisfy this recommendation. With obesity being a growing public health issue in the US, it is more than critical that Americans meet these recommendations by the CDC as there are harmful effects associated with not getting enough physical activity. These effects include being at a higher likelihood of developing high blood pressure, high blood cholesterol, type 2 diabetes, heart disease, and cancer; while the benefits vastly improves quality of life with improved sleep, cognitive ability, musculoskeletal health, and a reduced risk of dementia. 

Using nutrition data provided by the CDC, we utilize regression approaches to investigate the relationship between the proportion of Americans that engage in muscle-strengthening activities on 2 or more days by State/District, and age groupings. Since the data is collected from 2011 to 2016, we also investigate if there has been a change in levels of engaging in muscle strengthening exercises over the years. We are interested in what factors contribute to satisfying the muscle-strengthening recommendations, and to see how the different groupings are related.


# Data Cleansing

```{r}
#This section of code loads in the data, deletes columns with extraeous information, and filters the data to Obesity/Weight Status

#loading data
data <- read.csv("nutrition_data.csv", header = TRUE,na.strings=c("","NA"))
min(data$YearEnd)
#Removing Redundant Columns
summary(data)
# Delete Location Desc - LocationAbbr is the same column
# Delete Datasource - All Data comes from the same location
# Delete Topic - Same information As Class
# Delete Data_value_Unit & Data_Value_Type - Unit is all NA and All the data is a value of a type
# Delete Data_Value_Alt - Same information as Data_Value
# Delete Data_Value_FootNote_Symbol & Data_Value_Footnote - Provides information about missing samples
# Delete Total - Adds in no information
# Delete ClassID, TopicID, QUestionID, DataValueTypeID, LocationID, StratificationCategoryID1, StratificationID1
# Delete Low_Confidence_Limit, High_Confidence_Limit, Sample Size - calulated confidence intervals for each sample size

#Other Notes
# Both Confidence Limits, Sample Size 
# Age, Education, Gender, Income, Race has a lot of missing Values
# Filter Class to Obesity/Weight Status - Physical Activity and Fruits and Vegetables are irrelevent to the data
# Question TBA

#deleting redundant values
data <-  data %>% select(-c(LocationAbbr,Datasource, Topic,Data_Value_Unit,Data_Value_Type,Data_Value_Alt,Data_Value_Footnote,Data_Value_Footnote_Symbol, Total, ClassID, TopicID, Data_Value_Unit, QuestionID, DataValueTypeID, LocationID, StratificationCategory1, StratificationCategoryId1,Stratification1, StratificationID1))

#Filtering the Data to focus on A SPECIFIC QUESTION, OVERWEIGHT IS REMOVED
summary(data$Class)
data <- data %>% filter(Class == "Physical Activity" & Question == "Percent of adults who engage in muscle-strengthening activities on 2 or more days a week") %>% select(-c(Question, Class))

#Checking for length of study (YearEnd - YearStart) to see if there's studies crossing multiple years
data %>% filter( YearEnd - YearStart > 0)
data <- data %>% select(-YearEnd)

#Removes Confidence Interval + Sample Size + Geolocation
data <- data %>% select(-c("Low_Confidence_Limit","High_Confidence_Limit","Sample_Size", "GeoLocation"))

#filtering to view age + filtering null GeoLocation Values
data <- data %>% filter(!as.character(LocationDesc) %in% c("National","Guam","Puerto Rico"), !is.na(Age.years.)) %>% select(-c(Education, Gender, Income, Race.Ethnicity))

#checks if there's any more missing values
summary(!is.na(data))
data <- droplevels(data)

head(data)
```
The nutrition data is comprised of multiple different surveys results investigating different socio-economic factors and their effects on a multitude of survey questions. The survey is set up so that only one measure of socio-economic status is reported for each survey question. We begin cleaning the data set by removing all redundant variables that contain the same information as another variable, footnotes, confidence intervals, and sample sizes for each survey. Furthermore, we see that there is no difference between the start and the end year of the survey, so we remove the end year. Finally, we filtered the data set to surveys that investigate the proportion of adults who engage in muscle-strengthening activities on 2 or more days a week and narrow our focus to only US States and Districts since not enough data was available from US territories.


# Data Description

```{r}
#Introducing a new value
data %>% filter(YearStart == 2011, LocationDesc == "Alabama",Age.years. == "18 - 24")

new_point <- data.frame(YearStart = 2011,LocationDesc = factor("Alabama"),Data_Value = 60, Age.years. = factor("18 - 24"))
data <- rbind(data,new_point)

```
Before we begin our exploratory analysis, we introduce the data point (YearStart = 2011, LocationDesc = Alabama, Data_Value = 70, Age.years. = 18 - 24) as an anomaly (PLEASE ADD A LONGER DESCRIPTION HERE)


```{r}
#Data Visualization - Distribution
data %>% ggplot(aes(x = YearStart)) + geom_bar() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Year") + ylab("Count") + ggtitle("Distribution of Data Collected Each Year")

data %>% ggplot(aes(x = LocationDesc)) + geom_bar() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("US State/District") + ylab("Count") + ggtitle("Distribution of Surveys Conducted in Each State/District")

data %>% ggplot(aes(x = Age.years.)) + geom_bar() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Age Grouping") + ylab("Count") + ggtitle("Distribution of Age Groupings")

data %>% ggplot(aes(x = Data_Value)) + geom_density()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Proportion of Adults That Satisfies CDC Recommendations For Muscle Strengthening Activities") + ylab("Density") + ggtitle("Density of Adults That Satisfies CDC Recommendations")


```
Due to the long name of `proportion of Americans that engage in muscle-strengthening activities on 2 or more days`, we have simplied the name to `Proportion` when performing out exploratory analysis. For this analysis we have identified 3 variables of use: Year, State/District, and age grouping. We first analyse the distribution of each one of these variables, from the above barcharts, it is evident that the surveys are evenly distributed throughout the years, State/District, and age groupings; with the extra data point that we have added, the year 2011, the State of Alabama, and the age grouping `18 - 24` each has one additional point. As well, when looking at the density of the proportion of adults that satisfy CDC recommendations for muscle strengthening activities, it has a large peak that is slightly above 25, and a smaller peak around 43, and is generally right skewed.

```{r}
#Data Visualization

# Year vs Work Out Rate
data %>% group_by(YearStart) %>% mutate(median_value = median(Data_Value)) %>% ggplot(aes(x = reorder(YearStart,median_value), y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Year") + ylab("Proportion") + ggtitle("Proportion of Adults That Satisfy CDC Guidelines vs Year")

# Age Group vs Work out Rate
data %>% group_by(Age.years.) %>%  ggplot(aes(x = Age.years., y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Age Grouping") + ylab("Proportion") + ggtitle("Proportion of Adults That Satisfy CDC Guidelines vs Age Groupings")

# State vs Work Out Rate
data %>% group_by(LocationDesc) %>% mutate(median_value = median(Data_Value)) %>% ggplot(aes(x = reorder(LocationDesc,median_value), y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("US State/District") + ylab("Proportion") + ggtitle("Proportion of Adults That Satisfy CDC Guidelines vs US State/District")

# Heatmap of states
data_temp <- data %>% rename("state" = "LocationDesc")
plot_usmap(data = data_temp, values = "Data_Value", color = "red", labels = TRUE) + scale_fill_continuous(name = "Proportion", label = scales::comma) + ggtitle("Heatmap of Adults that Satisfy CDC Guidelines for Muscle Strengthening Exercise")

#pairs plot for correlation
pairs(data)
```
We now investigate the relationship between each explanatory variable with the response variable, meaning we would able to explain the variability of the response variable using the explanatory variable.

We start by exploring the change in the proportion of Americans that engage in muscle-strengthening activities for two or more days in a year. Each year has a similar IQR with the distribution slightly increasing as the years advance, which implies a linear relationship. In this boxplot, the new point is an extreme outlier for the 2011 boxplot, otherwise, there exist very few outliers in this boxplot.

When we compare age groupings to the proportion of Americans that engage in muscle-strengthening activities on two or more day's the relationship becomes clear. As age increases, we see a  negative linear relationship showing that younger Americans are more likely to work out in comparison to older Americans. An interesting observation with this boxplot is that there exist more outlier points of Americans who engage in fewer muscle-strengthening activities corresponding to their age grouping than Americans who engage in more muscle-strengthening activities within their age group.

We compare to see if there is a difference in the proportion of Americans that engage in muscle-strengthening activities on two or more days by State. This boxplot is arranged by increasing medians and there is clear evidence that the proportions are different by State, as the IQR for West Virginia and Colorado has no overlapping values. West Virginia has the lowest median proportion being just under 20, while Colorado has the highest median value over 30. To visualize this clearer on a map, we have also produced a heat map of the proportion by State/District.

Lastly, we look at the pairs plot to check for relationships between each variable. When looking at the layout between explanatory variables there isn't a linear relationship as the data appears to be uniform. When comparing each explanatory variable to Data_Value, we see a clear linear relationship with Age.years., a slight linear relationship with Year, and of the plot, LocationDesc is harder to interpret, but the data primarily looks randomly distributed.

# Methods
```{r}
# Train/Test Split (80/20)

set.seed(2928893)
test.size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = test.size)

data.train <- data[train_ind,]
data.test <- data[-train_ind,]

row.names(data.train) <- NULL
rownames(data.test) <- NULL

```
Before we build the regression models, we first split the data into a 80/20 train/test split for model testing and training.



```{r}
# Hypothesis testing - Model Building

#linear regression - no interaction
train.lm <- lm(Data_Value ~., data.train)

train.lm.noyears <- lm(Data_Value ~ LocationDesc + Age.years., data.train)

#interaction Model on Age
train.lm.age <- lm(Data_Value ~  YearStart*Age.years. + LocationDesc, data.train)

#interaction Model on Location
train.lm.loc <- lm(Data_Value ~  YearStart*LocationDesc + Age.years., data.train)

#interaction model on all 
train.lm.all <- lm(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, data.train)

```
We are also curious if the slopes of the regression line depends on the different factor levels for the Age Grouping and the State/District. We perform these hypothesis tests below. We train a linear regression model with no interaction terms on the training data, as well as create models with interaction terms on age groupings, State/District, and both age groupings and State/District also using the training data.


```{r}
#Hypothesis Testing - Importance of Age.years
anova(train.lm, train.lm.noyears)
```
In our exploratory data analysis, we saw that the proportion slightly grew as the year increased, we first want to test the significance of year given the other explanatory variables are included in the model. Using an ANOVA test to compare the full model with no interaction to the model without year and no interaction we get a p-value < 0.05, which suggests that the year is significant given all other variables are included in the model.



```{r}
#Hypothesis Testing - Interaction on age
anova(train.lm,train.lm.age)

```
We are curious if the slope for each age grouping are equal by adding an interaction term with age grouping and year. We compare this model with the full linear regression model using the ANOVA test. The result of this test provided us with a P-value < 0.05, suggesting that these two models are not the same, and that the interaction term is significant.


```{r}
#Hypothesis Testing - Interaction on location
anova(train.lm, train.lm.loc)

```
Similar to above, we now want to test if the slopes are the same for US States/Districts by adding an interaction term with State/Districts and year. We compare this model with the full linear regression model using the ANOVA test. The result of this test provided us with a P-value < 0.05, suggesting that these two models are not the same, and that the interaction term is significant.


```{r}
#Hypothesis Testing - Interaction on All
anova(train.lm.age, train.lm.all)

```
The last hypothesis test we perform is to test if the slopes are the same for the model with only the interaction term with age groupings and year and the model with both interactions terms on age grouping & year and State/District & year. Similar to our other hypothesis tests we use an ANOVA test that provides us with a p-value < 0.05, suggesting that the model with both interactions is different than the model with only the one interaction.

From these hypothesis tests, there is significant evidence that the slopes for different levels of the age grouping and State/District are different and we are more inclined to use the model with both interaction terms. 

```{r}
# Model Selection - Building Models

#10 fold cross validation for comparision
control <- trainControl(method = "cv", number = 10,returnResamp="all")

#linear regression - no interaction
set.seed(2928893)
mod.lm <- train(Data_Value ~ ., method = "lm", trControl = control, data.train)
mod.lm.RMSE <- mod.lm$resample[,"RMSE"]
mod.lm.r2 <- mod.lm$resample[,"Rsquared"]

#Stepwise regression w/ BIC - no interaction
set.seed(2928893)
mod.step <- train(Data_Value ~., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.RMSE <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"RMSE"]
mod.step.r2 <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"Rsquared"]

## MODELS WITH 1 INTERACTION

#linear Regression - interaction on Age years
set.seed(2928893)
mod.lm.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.age.RMSE <- mod.lm.age$resample[,"RMSE"]
mod.lm.age.r2 <- mod.lm.age$resample[,"Rsquared"]

#linear Regression - interaction on LocationDesc
set.seed(2928893)
mod.lm.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "lm", trControl = control, data.train)
mod.lm.loc.RMSE <- mod.lm.loc$resample[,"RMSE"]
mod.lm.loc.r2 <- mod.lm.loc$resample[,"Rsquared"]

#Stepwise regression w/ BIC - interaction on Age years
set.seed(2928893)
mod.step.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.age.RMSE <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"RMSE"]
mod.step.age.r2 <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"Rsquared"]

#Stepwise regression w/ BIC - interaction on LocationDesc
set.seed(2928893)
mod.step.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.loc.RMSE <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"RMSE"]
mod.step.loc.r2 <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"Rsquared"]



##MODELS WITH ALL INTERACTION TERMS

#linear Regression - all interaction
set.seed(2928893)
mod.lm.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.intr.RMSE <- mod.lm.intr$resample[,"RMSE"]
mod.lm.intr.r2 <- mod.lm.intr$resample[,"Rsquared"]

#Stepwise regression w/ all interaction
set.seed(2928893)
mod.step.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.intr.RMSE <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"RMSE"]
mod.step.intr.r2 <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"Rsquared"]

```
We now start to build our regression models and start tuning parameters if nessesary. Using the Caret package, for each model we build we perform 10-fold cross validation using our training data. We then save the computed $R^2$ value and the root-MSPE for each fold in each model. 

Although we have completed hypothesis testing to test if interaction terms are nessesary, we still use the models that we have rejected. Specifically we fit the following models:

Linear Model- No Interaction: $y = \beta_0 + \beta_1 x_{year} + \beta_2 x_{State/District} + \beta_3 x_{Age}$

Linear Model - Age Interaction: $y = \beta_0 + \beta_1 x_{year} + \beta_2 x_{State/District} + \beta_3 x_{Age} + \beta_4 x_{Age} x_{year}$

Linear Model - State/District Interaction: $y = \beta_0 + \beta_1 x_{year} + \beta_2 x_{State/District} + \beta_3 x_{Age} + \beta_4 x_{State/District} x_{year}$

Linear Model - Both State/District and Age Interaction: $y = \beta_0 + \beta_1 x_{year} + \beta_2 x_{State/District} + \beta_3 x_{Age} + \beta_4 x_{State/District} x_{year} + \beta_5 x_{Age} x_{year}$

As well, for each one of the models listed above, we also perform stepwise variable selection with parameter tuning from using 10-Fold Cross Validation.



```{r}
#Model Selection - Comparing Models

#Collecting the Errors
rMSPE <- as.matrix(cbind(mod.lm.RMSE, mod.lm.age.RMSE,mod.lm.loc.RMSE,mod.lm.intr.RMSE, mod.step.RMSE, mod.step.age.RMSE,mod.step.loc.RMSE,mod.step.intr.RMSE))
r2 <- as.matrix(cbind(mod.lm.r2, mod.lm.age.r2,mod.lm.loc.r2,mod.lm.intr.r2, mod.step.r2, mod.step.age.r2,mod.step.loc.r2,mod.step.intr.r2))

colnames(rMSPE) <- substr(colnames(rMSPE),1,nchar(colnames(rMSPE)) - 5)
colnames(r2) <- substr(colnames(r2),1,nchar(colnames(r2)) - 3)

mins.MSPE <- apply(rMSPE,1,min)
mins.r2 <- apply(r2,1,max)

#visualizations
boxplot(rMSPE, las = 2, main = "root-MSPE from 10-Fold CV", xlab = "model", ylab = "root-MSPE")
boxplot(rMSPE/mins.MSPE, las = 2, main = "Relative-root-MSPE from 10-Fold CV",xlab = "model", ylab = "Relative root-MSPE")
boxplot(r2, las = 2, main = "R2 value from 10-Fold CV", xlab = "model", ylab = "R2")


## All of the LM models perform decently well
```
With the $R^2$ and the root-MSPE saved from the 10-fold cross validation results, we create boxplots to compare the models.

From the first boxplot with the root-MSPE values, it is obvious that none of the stepwise regression models performed as well as the linear regression models. When comparing the linear regression models, the model with both interaction terms has the lowest median value, but as a slightly wider IQR than other linear regression models. The performance of all linear regression models are very similar, but the model with an interaction on age performs slightly better than the others with its slightly lower IQR.

To compare which models performed best in each fold, we create a Relative-root MSPE boxplot by dividing all of the root-MSPE values in each fold by the smallest error in that fold, using this method we're able to easier compare the performance of the models relative to each other. Similar to the MSPE boxplot, all stepwise regression models perform very poorly, while the linear regression model with the interaction term on age performs the best. From this boxplot, we're also able to tell that the linear model with no interactions terms is a close second contender for being the best model with a similar IQR, but a higher median value.

Lastly, we produced boxplots for the $R^2$ value in each fold of each model. Being consistent witht the other plots, the linear regression model with the interaction term on age has the best $R^2$ boxplot with both a high median value and a tight IQR in the model, as well, the linear regression model with no interaction terms followly closely, having a slightly lower median value, but similar IQR.


```{r}
## RESULTS

mod.lm.pred <- predict(mod.lm, newdata = data.test)
mod.lm.age.pred <- predict(mod.lm.age, newdata = data.test)
mod.lm.loc.pred <- predict(mod.lm.loc, newdata = data.test)
mod.lm.intr.pred <- predict(mod.lm.intr, newdata = data.test)

mod.step.pred <- predict(mod.step, newdata = data.test)
mod.step.age.pred <- predict(mod.step.age, newdata = data.test)
mod.step.loc.pred <- predict(mod.step.loc, newdata = data.test)
mod.step.intr.pred <- predict(mod.step.intr, newdata = data.test)

pred <- cbind(mod.lm.pred, mod.lm.age.pred,mod.lm.loc.pred
              ,mod.lm.intr.pred, mod.step.pred, mod.step.age.pred,mod.step.loc.pred
              ,mod.step.intr.pred)


calculateMSPE <- function(mod,test){
  result <- matrix(nrow = 1, ncol = ncol(mod))
  colnames(result) <- colnames(mod)
  for(i in 1:ncol(mod)){
    result[i] <- mean((test$Data_Value - mod[,i])^2)  
  }
  result
}

calculateR2 <- function(mod,test){
  result <- matrix(nrow = 1, ncol = ncol(mod))
  colnames(result) <- colnames(mod)
  for(i in 1:ncol(mod)){
    result[i] <- cor(mod[,i],test$Data_Value)^2
  }
  result
}


MSPE.test <- calculateMSPE(pred,data.test)
MSPE.test
# MODEL WITH AGE INTERACTION WITH STATE PERFORMS THE BEST
r2.test <- calculateR2(pred, data.test)
r2.test
#Testing with an abline
plot(data.test$Data_Value, mod.lm.intr.pred)
abline(c(0,1))

```
For the last step in model selection, we use the models that we built and tuned and compute its MSPE and $R^2$ on the testing data to see how the model performs with new data. In the previous boxplots, we saw that the linear regression model with no interaction terms and the linear regression model with the interaction term on age performed closely, with the model with the interaction term on age performing slightly better. In the test set, on the other hand the linear regression model with no interaction terms performed the best in terms of both $R^2$ and MSPE values; and since their performance were very similar during cross-validation, we select the linear regression model with no interaction terms based on its performance with the testing data.

#Residual Analysis 

After we have selected our best performing models, we now perform residual analysis to see if our model satisfies the assumptions for regression analysis.

```{r}
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel)
summary(mod.lm$finalModel)
```
We first perform the significance of regression test to see if the response and the regressors are at least linearly related.

$H_o: \beta_0 = \beta_1 = ... = \beta_{57}$

$H_a:$ There exists a $\beta_i \not = 0$

From the summary of the linear model, the p-value for this test is < 0.05, which suggests that there is a linear relationship between at least one of the regressors and the response.

```{r}
#Residual Analysis

plot(mod.lm.intr$finalModel)
#Checking assumptions of linear Regression
#1-Independence of observations is assumed 
#2-Linearity is satisfied from the given q-q plot
#3-Normality is confirmed due to distribution of the residual in Histogram
#4-heteroscedasticity is true since median is centered around 0 and distribution around it is pretty even
```
We then plot the residuals and check if they satisfy our assumptions. 

By looking at the Residual vs Fitted plot, all the points are randomly scattered with mean 0 and no clear pattern, which suggests that the constant variance assumption is satisfied.

The Normal Q-Q plot, for the majority follows a straight line behavious with few points around the edges of both extremes deviating from the line. From this observation, the normality of the residuals is satisfied.

For the standardized residuals vs leverage plot, the points for leverage are scattered evenly with a couple of points having high leverage, but since they do not have an standardized residual beyond +/- 3, they are no influential points. As well, there exist a couple points with standardizes residuals beyond +/- 3, but since they do not have a high leverage point, they are no influential.


```{r}
vif(mod.lm$finalModel)
#VIF values are all below 5 so we know there is no multicolinarity problems in the dataset
```
To check for multicollinearity issues within the model, we use the Variance Inflation Factor (VIF). The computed VIF for each variable is between (1,2), suggesting that there is not an issue with multicollinearity. 



```{r}
#Check for influential points
cooksd <- cooks.distance(mod.lm$finalModel)
which(cooksd > 1)
```
For the last section of residual analysis we look for possible influential points by using cooks distance and by checking $H_{i,i}$ & studentized residuals.

For Cook's Distance we consider a Cook's Distance > 1 to be influential. We compute Cook's Distance using the cooks.distance() function and checked if any values are > 1, since no values appeared, Cook's Distance suggests that there are no influential points.

```{r}
#leverage points

#High H_ii values
H <- diag(lm.influence(mod.lm$finalModel)$hat)
p <- length(mod.lm$finalModel$coefficients)

2*p/nrow(data.train)


which(H > 2*p/nrow(data.train), arr.ind = TRUE)

#Large Residuals

student.resid <- rstudent(mod.lm$finalModel)
which(abs(student.resid) >= 3)


##The points 160 has a high H_ii and has a large residual

#data.train[160,]
```
We now check for influential points by using $H_{i,i}$ and studentized residual values. We first compute $\frac{2p}{n}$ and check if it's > 1. Since it is not, we can use the $H_{i,i} > \frac{2p}{n}$ rule of thumb to check for leverage points. No points are identified as high leverage points using this rule of thumb.

For the studentized residuals, we are looking for residuals that are beyond +/- 3. The standardized residuals are computed first and then we check for any points with large residuals. Multiple different points are seen, and they are reported above in the R Script, but since there does are no points with both a high leverage and a large studentized residual, there are no influential points

# Conclusion or something





