---
title: "STAT 350 - Project"
author: "Kevin He"
date: "11/21/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#loading libraries
library(tidyverse)
library(caret)
library(faraway)
library(usmap)
```


# Abstract
- State something here about the problem
- State something quick procedures (perform regression analysis with these methods)
- Briefly Summarize Conclusion

# Introduction
-Obesity has become a growing problem in the United States. We will be investigating the percent of adults who 
-engage in muscle-strengthening activities on 2 or more days a week by age group by performing a complete 
-regression analysis of CDC Data: Nutrition, Physical Activity, & Obesity. We will start by data cleaning to 
-filter the data to Obesity/Weight Status, focusing on working out two times a week by group and age. We will be 
-selecting a linear regression model using various selection methods such as stepwise and cross validation methods. 
-We will also conduct full analysis of the selected model to help interpret the results.
- Research Question: Percent of adults who engage in muscle-strengthening activities on 2 or more days a week by age group

# Data Description

```{r}
#This section of code loads in the data, deletes columns with extraeous information, and filters the data to Obesity/Weight Status

#loading data
data <- read.csv("nutrition_data.csv", header = TRUE,na.strings=c("","NA"))
#Removing Redundant Columns
summary(data)
# Delete Location Desc - LocationAbbr is the same column
# Delete Datasource - All Data comes from the same location
# Delete Topic - Same information As Class
# Delete Data_value_Unit & Data_Value_Type - Unit is all NA and All the data is a value of a type
# Delete Data_Value_Alt - Same information as Data_Value
# Delete Data_Value_FootNote_Symbol & Data_Value_Footnote - Provides information about missing samples
# Delete Total - Adds in no information
# Delete ClassID, TopicID, QUestionID, DataValueTypeID, LocationID, StratificationCategoryID1, StratificationID1
# Delete Low_Confidence_Limit, High_Confidence_Limit, Sample Size - calulated confidence intervals for each sample size

#Other Notes
# Both Confidence Limits, Sample Size 
# Age, Education, Gender, Income, Race has a lot of missing Values
# Filter Class to Obesity/Weight Status - Physical Activity and Fruits and Vegetables are irrelevent to the data
# Question TBA

#deleting redundant values
data <-  data %>% select(-c(LocationAbbr,Datasource, Topic,Data_Value_Unit,Data_Value_Type,Data_Value_Alt,Data_Value_Footnote,Data_Value_Footnote_Symbol, Total, ClassID, TopicID, Data_Value_Unit, QuestionID, DataValueTypeID, LocationID, StratificationCategory1, StratificationCategoryId1,Stratification1, StratificationID1))

#Filtering the Data to focus on A SPECIFIC QUESTION, OVERWEIGHT IS REMOVED
summary(data$Class)
data <- data %>% filter(Class == "Physical Activity" & Question == "Percent of adults who engage in muscle-strengthening activities on 2 or more days a week") %>% select(-c(Question, Class))

#Checking for length of study (YearEnd - YearStart) to see if there's studies crossing multiple years
data %>% filter( YearEnd - YearStart > 0)
data <- data %>% select(-YearEnd)

#Removes Confidence Interval + Sample Size + Geolocation
data <- data %>% select(-c("Low_Confidence_Limit","High_Confidence_Limit","Sample_Size", "GeoLocation"))
data <- droplevels(data)

head(data)
```

```{r}
#data Clensing pt2 -- Focused on Working out 2x a week by group and age

#filtering to view age + filtering null GeoLocation Values
data <- data %>% filter(!as.character(LocationDesc) %in% c("National","Guam","Puerto Rico"), !is.na(Age.years.)) %>% select(-c(Education, Gender, Income, Race.Ethnicity))

#checks if there's any more missing values
summary(!is.na(data))
data <- droplevels(data)

```

```{r}
#Introducing a new value
new_point <- data.frame(YearStart = 2011,LocationDesc = factor("California"),Data_Value = 60, Age.years. = factor("18 - 24"))
data <- rbind(data,new_point)

```

```{r}
#Data Visualization

# Year vs Work Out Rate
data %>% group_by(YearStart) %>% mutate(median_value = median(Data_Value)) %>% ggplot(aes(x = reorder(YearStart,median_value), y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Year") + ylab("Workout Rate")

# State vs Work Out Rate
data %>% group_by(LocationDesc) %>% mutate(median_value = median(Data_Value)) %>% ggplot(aes(x = reorder(LocationDesc,median_value), y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("US State/Territory") + ylab("Workout Rate")

# Age Group vs Work out Rate
data %>% group_by(Age.years.) %>% mutate(median_value = median(Data_Value)) %>% ggplot(aes(x = Age.years., y = Data_Value)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + xlab("Age Grouping") + ylab("Workout Rate")

# Heatmap of states
data_temp <- data %>% rename("state" = "LocationDesc")
plot_usmap(data = data_temp, values = "Data_Value", color = "red", labels = TRUE) + scale_fill_continuous(name = "Work Out Rate", label = scales::comma)

#pairs plot for correlation
pairs(data)
```

```{r}
# Train/Test Split (80/20)

set.seed(2928893)
test.size <- floor(0.8 * nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = test.size)

data.train <- data[train_ind,]
data.test <- data[-train_ind,]

row.names(data.train) <- NULL
rownames(data.test) <- NULL

```

```{r}
# Hypothesis testing - Model Building

#linear regression - no interaction
train.lm <- lm(Data_Value ~., data.train)

train.lm.noyears <- lm(Data_Value ~ LocationDesc + Age.years., data.train)

#interaction Model on Age
train.lm.age <- lm(Data_Value ~  YearStart*Age.years. + LocationDesc, data.train)

#interaction Model on Location
train.lm.loc <- lm(Data_Value ~  YearStart*LocationDesc + Age.years., data.train)

#interaction model on all 
train.lm.all <- lm(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, data.train)

```

```{r}
#Hypothesis Testing - Importance of Age.years
anova(train.lm, train.lm.noyears)
```

```{r}
#Hypothesis Testing - Interaction on age
anova(train.lm,train.lm.age)

```

```{r}
#Hypothesis Testing - Interaction on location
anova(train.lm, train.lm.loc)

```

```{r}
#Hypothesis Testing - Interaction on All
anova(train.lm, train.lm.all)

```


```{r}
# Model Selection - Building Models

#10 fold cross validation for comparision
control <- trainControl(method = "cv", number = 10,returnResamp="all")

#linear regression - no interaction
set.seed(2928893)
mod.lm <- train(Data_Value ~ ., method = "lm", trControl = control, data.train)
mod.lm.RMSE <- mod.lm$resample[,"RMSE"]
mod.lm.r2 <- mod.lm$resample[,"Rsquared"]

#Stepwise regression w/ BIC - no interaction
set.seed(2928893)
mod.step <- train(Data_Value ~., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.RMSE <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"RMSE"]
mod.step.r2 <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"Rsquared"]

## MODELS WITH 1 INTERACTION

#linear Regression - interaction on Age years
set.seed(2928893)
mod.lm.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.age.RMSE <- mod.lm.age$resample[,"RMSE"]
mod.lm.age.r2 <- mod.lm.age$resample[,"Rsquared"]

#linear Regression - interaction on LocationDesc
set.seed(2928893)
mod.lm.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "lm", trControl = control, data.train)
mod.lm.loc.RMSE <- mod.lm.loc$resample[,"RMSE"]
mod.lm.loc.r2 <- mod.lm.loc$resample[,"Rsquared"]

#Stepwise regression w/ BIC - interaction on Age years
set.seed(2928893)
mod.step.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.age.RMSE <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"RMSE"]
mod.step.age.r2 <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"Rsquared"]

#Stepwise regression w/ BIC - interaction on LocationDesc
set.seed(2928893)
mod.step.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.loc.RMSE <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"RMSE"]
mod.step.loc.r2 <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"Rsquared"]



##MODELS WITH ALL INTERACTION TERMS

#linear Regression - all interaction HAS A COUPLE OF NA'S
set.seed(2928893)
mod.lm.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.intr.RMSE <- mod.lm.intr$resample[,"RMSE"]
mod.lm.intr.r2 <- mod.lm.intr$resample[,"Rsquared"]

#Stepwise regression w/ all interaction - HAS A COUPLE OF NA'S
set.seed(2928893)
mod.step.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.intr.RMSE <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"RMSE"]
mod.step.intr.r2 <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"Rsquared"]

```

```{r}
#Model Selection - Comparing Models - Models with NA are removed

#Collecting the Errors
rMSPE <- as.matrix(cbind(mod.lm.RMSE, mod.lm.age.RMSE,mod.lm.loc.RMSE,mod.lm.intr.RMSE, mod.step.RMSE, mod.step.age.RMSE,mod.step.loc.RMSE,mod.step.intr.RMSE))
r2 <- as.matrix(cbind(mod.lm.r2, mod.lm.age.r2,mod.lm.loc.r2,mod.lm.intr.r2, mod.step.r2, mod.step.age.r2,mod.step.loc.r2,mod.step.intr.r2))

colnames(rMSPE) <- substr(colnames(rMSPE),1,nchar(colnames(rMSPE)) - 5)
colnames(r2) <- substr(colnames(r2),1,nchar(colnames(r2)) - 3)

mins.MSPE <- apply(rMSPE,1,min)
mins.r2 <- apply(r2,1,max)

#visualizations
boxplot(rMSPE, las = 2, main = "root-MSPE from 10-Fold CV")
boxplot(rMSPE/mins.MSPE, las = 2, main = "Relative-root-MSPE from 10-Fold CV")
boxplot(r2, las = 2, main = "R2 value from 10-Fold CV")


## All of the LM models perform decently well
```



```{r}
## RESULTS

mod.lm.pred <- predict(mod.lm, newdata = data.test)
mod.lm.age.pred <- predict(mod.lm.age, newdata = data.test)
mod.lm.loc.pred <- predict(mod.lm.loc, newdata = data.test)
mod.lm.intr.pred <- predict(mod.lm.intr, newdata = data.test)

mod.step.pred <- predict(mod.step, newdata = data.test)
mod.step.age.pred <- predict(mod.step.age, newdata = data.test)
mod.step.loc.pred <- predict(mod.step.loc, newdata = data.test)
mod.step.intr.pred <- predict(mod.step.intr, newdata = data.test)

pred <- cbind(mod.lm.pred, mod.lm.age.pred,mod.lm.loc.pred
              ,mod.lm.intr.pred, mod.step.pred, mod.step.age.pred,mod.step.loc.pred
              ,mod.step.intr.pred)


calculateMSPE <- function(mod,test){
  result <- matrix(nrow = 1, ncol = ncol(mod))
  colnames(result) <- colnames(mod)
  for(i in 1:ncol(mod)){
    result[i] <- mean((test$Data_Value - mod[,i])^2)  
  }
  result
}

calculateR2 <- function(mod,test){
  result <- matrix(nrow = 1, ncol = ncol(mod))
  colnames(result) <- colnames(mod)
  for(i in 1:ncol(mod)){
    result[i] <- cor(mod[,i],test$Data_Value)^2
  }
  result
}


MSPE.test <- calculateMSPE(pred,data.test)
MSPE.test
# MODEL WITH AGE INTERACTION WITH STATE PERFORMS THE BEST
r2.test <- calculateR2(pred, data.test)
r2.test
#Testing with an abline
plot(data.test$Data_Value, mod.lm.intr.pred)
abline(c(0,1))

```



```{r}
summary(mod.lm.intr$finalModel)
# reject null since p-value is smaller than 0.05 significance
```

```{r}
#Residual Analysis

plot(mod.lm.intr$finalModel)
#Checking assumptions of linear Regression
#1-Independence of observations is assumed 
#2-Linearity is satisfied from the given q-q plot
#3-Normality is confirmed due to distribution of the residual in Histogram
#4-heteroscedasticity is true since median is centered around 0 and distribution around it is pretty even
```

```{r}
vif(mod.lm$finalModel)
#VIF values are all below 5 so we know there is no multicolinarity problems in the dataset
```

```{r}
plot(mod.lm.intr$finalModel$residuals)
#confirms constant varience, is in agreement with summary data with median being around 0 and data distributed 
#equally
```

```{r}
#As we can see there are some outliers but we cant take them out since it would affect the model.
cooksd <- cooks.distance(mod.lm.intr$finalModel)
which(cooksd > 1)
```

```{r}
#leverage points

#High H_ii values
H <- diag(lm.influence(mod.lm.intr$finalModel)$hat)
mean(H)

p <- length(mod.lm.intr$finalModel$coefficients)
which(H > 2*p/nrow(data.train), arr.ind = TRUE)

#Large Residuals

student.resid <- rstudent(mod.lm.intr$finalModel)
which(abs(student.resid) >= 3)


##The points 160 has a high H_ii and has a large residual

#data.train[160,]
```

```{r}


```




