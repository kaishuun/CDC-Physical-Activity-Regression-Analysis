mins.r2 <- apply(r2,1,max)
#visualizations
boxplot(rMSPE, las = 2, main = "root-MSPE from 10-Fold CV", xlab = "model", ylab = "root-MSPE")
boxplot(rMSPE/mins.MSPE, las = 2, main = "Relative-root-MSPE from 10-Fold CV",xlab = "model", ylab = "Relative root-MSPE")
boxplot(r2, las = 2, main = "R2 value from 10-Fold CV", xlab = "model", ylab = "R2")
## All of the LM models perform decently well
## RESULTS
mod.lm.pred <- predict(mod.lm, newdata = data.test)
mod.lm.age.pred <- predict(mod.lm.age, newdata = data.test)
mod.lm.loc.pred <- predict(mod.lm.loc, newdata = data.test)
mod.lm.intr.pred <- predict(mod.lm.intr, newdata = data.test)
mod.step.pred <- predict(mod.step, newdata = data.test)
mod.step.age.pred <- predict(mod.step.age, newdata = data.test)
mod.step.loc.pred <- predict(mod.step.loc, newdata = data.test)
mod.step.intr.pred <- predict(mod.step.intr, newdata = data.test)
pred <- cbind(mod.lm.pred, mod.lm.age.pred,mod.lm.loc.pred
,mod.lm.intr.pred, mod.step.pred, mod.step.age.pred,mod.step.loc.pred
,mod.step.intr.pred)
calculateMSPE <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- mean((test$Data_Value - mod[,i])^2)
}
result
}
calculateR2 <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- cor(mod[,i],test$Data_Value)^2
}
result
}
MSPE.test <- calculateMSPE(pred,data.test)
MSPE.test
# MODEL WITH AGE INTERACTION WITH STATE PERFORMS THE BEST
r2.test <- calculateR2(pred, data.test)
r2.test
#Testing with an abline
plot(data.test$Data_Value, mod.lm.intr.pred)
abline(c(0,1))
summary(mod.lm$finalModel)
#Residual Analysis
plot(mod.lm.intr$finalModel)
#Checking assumptions of linear Regression
#1-Independence of observations is assumed
#2-Linearity is satisfied from the given q-q plot
#3-Normality is confirmed due to distribution of the residual in Histogram
#4-heteroscedasticity is true since median is centered around 0 and distribution around it is pretty even
vif(mod.lm$finalModel)
#VIF values are all below 5 so we know there is no multicolinarity problems in the dataset
#Check for influential points
cooksd <- cooks.distance(mod.lm$finalModel)
which(cooksd > 1)
#leverage points
#High H_ii values
H <- diag(lm.influence(mod.lm$finalModel)$hat)
p <- length(mod.lm$finalModel$coefficients)
2*p/nrow(data.train)
which(H > 2*p/nrow(data.train), arr.ind = TRUE)
#Large Residuals
student.resid <- rstudent(mod.lm$finalModel)
which(abs(student.resid) >= 3)
##The points 160 has a high H_ii and has a large residual
#data.train[160,]
prestige.rmod <- rlm(prestige ~ education + income + type, p6data, psi = psi.huber)
library(MASS)
prestige.rmod <- rlm(prestige ~ education + income + type, p6data, psi = psi.huber)
p6data <- read.csv("/Users/ashutoshdubal/Desktop/prestige.csv")
#Question 1(a)
prestige.mod <- lm(prestige ~ education + income + type, p6data)
summary(prestige.mod)
#Question 1(a)
prestige.mod <- lm(prestige ~ education + income + type, p6data)
p6data <- read.csv("/Users/ashutoshdubal/Desktop/prestige.csv")
#Question 1(a)
prestige.mod <- lm(prestige ~ education + income + type, p6data)
summary(prestige.mod)
library(MASS)
prestige.rmod <- rlm(prestige ~ education + income + type, p6data, psi = psi.huber)
summary(prestige.rmod)
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel, k = 2)
summary(mod.lm$finalModel)
# Model Selection - Building Models
#10 fold cross validation for comparision
control <- trainControl(method = "cv", number = 10,returnResamp="all")
#linear regression - no interaction
set.seed(10000)
mod.lm <- train(Data_Value ~ ., method = "lm", trControl = control, data.train)
mod.lm.RMSE <- mod.lm$resample[,"RMSE"]
mod.lm.r2 <- mod.lm$resample[,"Rsquared"]
#Stepwise regression w/ BIC - no interaction
set.seed(2928893)
mod.step <- train(Data_Value ~., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.RMSE <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"RMSE"]
mod.step.r2 <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"Rsquared"]
## MODELS WITH 1 INTERACTION
#linear Regression - interaction on Age years
set.seed(10000)
mod.lm.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.age.RMSE <- mod.lm.age$resample[,"RMSE"]
mod.lm.age.r2 <- mod.lm.age$resample[,"Rsquared"]
#linear Regression - interaction on LocationDesc
set.seed(10000)
mod.lm.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "lm", trControl = control, data.train)
mod.lm.loc.RMSE <- mod.lm.loc$resample[,"RMSE"]
mod.lm.loc.r2 <- mod.lm.loc$resample[,"Rsquared"]
#Stepwise regression w/ BIC - interaction on Age years
set.seed(2928893)
mod.step.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.age.RMSE <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"RMSE"]
mod.step.age.r2 <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"Rsquared"]
#Stepwise regression w/ BIC - interaction on LocationDesc
set.seed(2928893)
mod.step.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.loc.RMSE <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"RMSE"]
mod.step.loc.r2 <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"Rsquared"]
##MODELS WITH ALL INTERACTION TERMS
#linear Regression - all interaction
set.seed(10000)
mod.lm.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.intr.RMSE <- mod.lm.intr$resample[,"RMSE"]
mod.lm.intr.r2 <- mod.lm.intr$resample[,"Rsquared"]
#Stepwise regression w/ all interaction
set.seed(2928893)
mod.step.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.intr.RMSE <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"RMSE"]
mod.step.intr.r2 <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"Rsquared"]
#Model Selection - Comparing Models
#Collecting the Errors
rMSPE <- as.matrix(cbind(mod.lm.RMSE, mod.lm.age.RMSE,mod.lm.loc.RMSE,mod.lm.intr.RMSE, mod.step.RMSE, mod.step.age.RMSE,mod.step.loc.RMSE,mod.step.intr.RMSE))
r2 <- as.matrix(cbind(mod.lm.r2, mod.lm.age.r2,mod.lm.loc.r2,mod.lm.intr.r2, mod.step.r2, mod.step.age.r2,mod.step.loc.r2,mod.step.intr.r2))
colnames(rMSPE) <- substr(colnames(rMSPE),1,nchar(colnames(rMSPE)) - 5)
colnames(r2) <- substr(colnames(r2),1,nchar(colnames(r2)) - 3)
mins.MSPE <- apply(rMSPE,1,min)
mins.r2 <- apply(r2,1,max)
#visualizations
boxplot(rMSPE, las = 2, main = "root-MSPE from 10-Fold CV", xlab = "model", ylab = "root-MSPE")
boxplot(rMSPE/mins.MSPE, las = 2, main = "Relative-root-MSPE from 10-Fold CV",xlab = "model", ylab = "Relative root-MSPE")
boxplot(r2, las = 2, main = "R2 value from 10-Fold CV", xlab = "model", ylab = "R2")
## All of the LM models perform decently well
## RESULTS
mod.lm.pred <- predict(mod.lm, newdata = data.test)
mod.lm.age.pred <- predict(mod.lm.age, newdata = data.test)
mod.lm.loc.pred <- predict(mod.lm.loc, newdata = data.test)
mod.lm.intr.pred <- predict(mod.lm.intr, newdata = data.test)
mod.step.pred <- predict(mod.step, newdata = data.test)
mod.step.age.pred <- predict(mod.step.age, newdata = data.test)
mod.step.loc.pred <- predict(mod.step.loc, newdata = data.test)
mod.step.intr.pred <- predict(mod.step.intr, newdata = data.test)
pred <- cbind(mod.lm.pred, mod.lm.age.pred,mod.lm.loc.pred
,mod.lm.intr.pred, mod.step.pred, mod.step.age.pred,mod.step.loc.pred
,mod.step.intr.pred)
calculateMSPE <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- mean((test$Data_Value - mod[,i])^2)
}
result
}
calculateR2 <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- cor(mod[,i],test$Data_Value)^2
}
result
}
MSPE.test <- calculateMSPE(pred,data.test)
MSPE.test
# MODEL WITH AGE INTERACTION WITH STATE PERFORMS THE BEST
r2.test <- calculateR2(pred, data.test)
r2.test
#Testing with an abline
plot(data.test$Data_Value, mod.lm.intr.pred)
abline(c(0,1))
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel, k = 2)
summary(mod.lm$finalModel)
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel, k = 2)
summary(mod.lm$finalModel)
# Model Selection - Building Models
#10 fold cross validation for comparision
control <- trainControl(method = "cv", number = 10,returnResamp="all")
#linear regression - no interaction
set.seed(1000)
mod.lm <- train(Data_Value ~ ., method = "lm", trControl = control, data.train)
mod.lm.RMSE <- mod.lm$resample[,"RMSE"]
mod.lm.r2 <- mod.lm$resample[,"Rsquared"]
#Stepwise regression w/ BIC - no interaction
set.seed(2928893)
mod.step <- train(Data_Value ~., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.RMSE <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"RMSE"]
mod.step.r2 <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"Rsquared"]
## MODELS WITH 1 INTERACTION
#linear Regression - interaction on Age years
set.seed(1000)
mod.lm.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.age.RMSE <- mod.lm.age$resample[,"RMSE"]
mod.lm.age.r2 <- mod.lm.age$resample[,"Rsquared"]
#linear Regression - interaction on LocationDesc
set.seed(1000)
mod.lm.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "lm", trControl = control, data.train)
mod.lm.loc.RMSE <- mod.lm.loc$resample[,"RMSE"]
mod.lm.loc.r2 <- mod.lm.loc$resample[,"Rsquared"]
#Stepwise regression w/ BIC - interaction on Age years
set.seed(2928893)
mod.step.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.age.RMSE <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"RMSE"]
mod.step.age.r2 <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"Rsquared"]
#Stepwise regression w/ BIC - interaction on LocationDesc
set.seed(2928893)
mod.step.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.loc.RMSE <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"RMSE"]
mod.step.loc.r2 <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"Rsquared"]
##MODELS WITH ALL INTERACTION TERMS
#linear Regression - all interaction
set.seed(1000)
mod.lm.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.intr.RMSE <- mod.lm.intr$resample[,"RMSE"]
mod.lm.intr.r2 <- mod.lm.intr$resample[,"Rsquared"]
#Stepwise regression w/ all interaction
set.seed(2928893)
mod.step.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.intr.RMSE <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"RMSE"]
mod.step.intr.r2 <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"Rsquared"]
#Model Selection - Comparing Models
#Collecting the Errors
rMSPE <- as.matrix(cbind(mod.lm.RMSE, mod.lm.age.RMSE,mod.lm.loc.RMSE,mod.lm.intr.RMSE, mod.step.RMSE, mod.step.age.RMSE,mod.step.loc.RMSE,mod.step.intr.RMSE))
r2 <- as.matrix(cbind(mod.lm.r2, mod.lm.age.r2,mod.lm.loc.r2,mod.lm.intr.r2, mod.step.r2, mod.step.age.r2,mod.step.loc.r2,mod.step.intr.r2))
colnames(rMSPE) <- substr(colnames(rMSPE),1,nchar(colnames(rMSPE)) - 5)
colnames(r2) <- substr(colnames(r2),1,nchar(colnames(r2)) - 3)
mins.MSPE <- apply(rMSPE,1,min)
mins.r2 <- apply(r2,1,max)
#visualizations
boxplot(rMSPE, las = 2, main = "root-MSPE from 10-Fold CV", xlab = "model", ylab = "root-MSPE")
boxplot(rMSPE/mins.MSPE, las = 2, main = "Relative-root-MSPE from 10-Fold CV",xlab = "model", ylab = "Relative root-MSPE")
boxplot(r2, las = 2, main = "R2 value from 10-Fold CV", xlab = "model", ylab = "R2")
## All of the LM models perform decently well
## RESULTS
mod.lm.pred <- predict(mod.lm, newdata = data.test)
mod.lm.age.pred <- predict(mod.lm.age, newdata = data.test)
mod.lm.loc.pred <- predict(mod.lm.loc, newdata = data.test)
mod.lm.intr.pred <- predict(mod.lm.intr, newdata = data.test)
mod.step.pred <- predict(mod.step, newdata = data.test)
mod.step.age.pred <- predict(mod.step.age, newdata = data.test)
mod.step.loc.pred <- predict(mod.step.loc, newdata = data.test)
mod.step.intr.pred <- predict(mod.step.intr, newdata = data.test)
pred <- cbind(mod.lm.pred, mod.lm.age.pred,mod.lm.loc.pred
,mod.lm.intr.pred, mod.step.pred, mod.step.age.pred,mod.step.loc.pred
,mod.step.intr.pred)
calculateMSPE <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- mean((test$Data_Value - mod[,i])^2)
}
result
}
calculateR2 <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- cor(mod[,i],test$Data_Value)^2
}
result
}
MSPE.test <- calculateMSPE(pred,data.test)
MSPE.test
# MODEL WITH AGE INTERACTION WITH STATE PERFORMS THE BEST
r2.test <- calculateR2(pred, data.test)
r2.test
#Testing with an abline
plot(data.test$Data_Value, mod.lm.intr.pred)
abline(c(0,1))
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel, k = 2)
summary(mod.lm$finalModel)
# Model Selection - Building Models
#10 fold cross validation for comparision
control <- trainControl(method = "cv", number = 10,returnResamp="all")
#linear regression - no interaction
set.seed(100)
mod.lm <- train(Data_Value ~ ., method = "lm", trControl = control, data.train)
mod.lm.RMSE <- mod.lm$resample[,"RMSE"]
mod.lm.r2 <- mod.lm$resample[,"Rsquared"]
#Stepwise regression w/ BIC - no interaction
set.seed(2928893)
mod.step <- train(Data_Value ~., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.RMSE <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"RMSE"]
mod.step.r2 <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"Rsquared"]
## MODELS WITH 1 INTERACTION
#linear Regression - interaction on Age years
set.seed(100)
mod.lm.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.age.RMSE <- mod.lm.age$resample[,"RMSE"]
mod.lm.age.r2 <- mod.lm.age$resample[,"Rsquared"]
#linear Regression - interaction on LocationDesc
set.seed(100)
mod.lm.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "lm", trControl = control, data.train)
mod.lm.loc.RMSE <- mod.lm.loc$resample[,"RMSE"]
mod.lm.loc.r2 <- mod.lm.loc$resample[,"Rsquared"]
#Stepwise regression w/ BIC - interaction on Age years
set.seed(2928893)
mod.step.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.age.RMSE <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"RMSE"]
mod.step.age.r2 <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"Rsquared"]
#Stepwise regression w/ BIC - interaction on LocationDesc
set.seed(2928893)
mod.step.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.loc.RMSE <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"RMSE"]
mod.step.loc.r2 <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"Rsquared"]
##MODELS WITH ALL INTERACTION TERMS
#linear Regression - all interaction
set.seed(100)
mod.lm.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.intr.RMSE <- mod.lm.intr$resample[,"RMSE"]
mod.lm.intr.r2 <- mod.lm.intr$resample[,"Rsquared"]
#Stepwise regression w/ all interaction
set.seed(2928893)
mod.step.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.intr.RMSE <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"RMSE"]
mod.step.intr.r2 <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"Rsquared"]
#Model Selection - Comparing Models
#Collecting the Errors
rMSPE <- as.matrix(cbind(mod.lm.RMSE, mod.lm.age.RMSE,mod.lm.loc.RMSE,mod.lm.intr.RMSE, mod.step.RMSE, mod.step.age.RMSE,mod.step.loc.RMSE,mod.step.intr.RMSE))
r2 <- as.matrix(cbind(mod.lm.r2, mod.lm.age.r2,mod.lm.loc.r2,mod.lm.intr.r2, mod.step.r2, mod.step.age.r2,mod.step.loc.r2,mod.step.intr.r2))
colnames(rMSPE) <- substr(colnames(rMSPE),1,nchar(colnames(rMSPE)) - 5)
colnames(r2) <- substr(colnames(r2),1,nchar(colnames(r2)) - 3)
mins.MSPE <- apply(rMSPE,1,min)
mins.r2 <- apply(r2,1,max)
#visualizations
boxplot(rMSPE, las = 2, main = "root-MSPE from 10-Fold CV", xlab = "model", ylab = "root-MSPE")
boxplot(rMSPE/mins.MSPE, las = 2, main = "Relative-root-MSPE from 10-Fold CV",xlab = "model", ylab = "Relative root-MSPE")
boxplot(r2, las = 2, main = "R2 value from 10-Fold CV", xlab = "model", ylab = "R2")
## All of the LM models perform decently well
## RESULTS
mod.lm.pred <- predict(mod.lm, newdata = data.test)
mod.lm.age.pred <- predict(mod.lm.age, newdata = data.test)
mod.lm.loc.pred <- predict(mod.lm.loc, newdata = data.test)
mod.lm.intr.pred <- predict(mod.lm.intr, newdata = data.test)
mod.step.pred <- predict(mod.step, newdata = data.test)
mod.step.age.pred <- predict(mod.step.age, newdata = data.test)
mod.step.loc.pred <- predict(mod.step.loc, newdata = data.test)
mod.step.intr.pred <- predict(mod.step.intr, newdata = data.test)
pred <- cbind(mod.lm.pred, mod.lm.age.pred,mod.lm.loc.pred
,mod.lm.intr.pred, mod.step.pred, mod.step.age.pred,mod.step.loc.pred
,mod.step.intr.pred)
calculateMSPE <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- mean((test$Data_Value - mod[,i])^2)
}
result
}
calculateR2 <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- cor(mod[,i],test$Data_Value)^2
}
result
}
MSPE.test <- calculateMSPE(pred,data.test)
MSPE.test
# MODEL WITH AGE INTERACTION WITH STATE PERFORMS THE BEST
r2.test <- calculateR2(pred, data.test)
r2.test
#Testing with an abline
plot(data.test$Data_Value, mod.lm.intr.pred)
abline(c(0,1))
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel, k = 2)
summary(mod.lm$finalModel)
# Model Selection - Building Models
#10 fold cross validation for comparision
control <- trainControl(method = "cv", number = 10,returnResamp="all")
#linear regression - no interaction
set.seed(5000)
mod.lm <- train(Data_Value ~ ., method = "lm", trControl = control, data.train)
mod.lm.RMSE <- mod.lm$resample[,"RMSE"]
mod.lm.r2 <- mod.lm$resample[,"Rsquared"]
#Stepwise regression w/ BIC - no interaction
set.seed(2928893)
mod.step <- train(Data_Value ~., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.RMSE <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"RMSE"]
mod.step.r2 <- mod.step$resample[mod.step$resample[,"nvmax"] == mod.step$bestTune[1,1],"Rsquared"]
## MODELS WITH 1 INTERACTION
#linear Regression - interaction on Age years
set.seed(5000)
mod.lm.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.age.RMSE <- mod.lm.age$resample[,"RMSE"]
mod.lm.age.r2 <- mod.lm.age$resample[,"Rsquared"]
#linear Regression - interaction on LocationDesc
set.seed(5000)
mod.lm.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "lm", trControl = control, data.train)
mod.lm.loc.RMSE <- mod.lm.loc$resample[,"RMSE"]
mod.lm.loc.r2 <- mod.lm.loc$resample[,"Rsquared"]
#Stepwise regression w/ BIC - interaction on Age years
set.seed(2928893)
mod.step.age <- train(Data_Value ~  YearStart*Age.years. + LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.age.RMSE <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"RMSE"]
mod.step.age.r2 <- mod.step.age$resample[mod.step.age$resample[,"nvmax"] == mod.step.age$bestTune[1,1],"Rsquared"]
#Stepwise regression w/ BIC - interaction on LocationDesc
set.seed(2928893)
mod.step.loc <- train(Data_Value ~  YearStart*LocationDesc + Age.years., method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.loc.RMSE <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"RMSE"]
mod.step.loc.r2 <- mod.step.loc$resample[mod.step.loc$resample[,"nvmax"] == mod.step.loc$bestTune[1,1],"Rsquared"]
##MODELS WITH ALL INTERACTION TERMS
#linear Regression - all interaction
set.seed(5000)
mod.lm.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "lm", trControl = control, data.train)
mod.lm.intr.RMSE <- mod.lm.intr$resample[,"RMSE"]
mod.lm.intr.r2 <- mod.lm.intr$resample[,"Rsquared"]
#Stepwise regression w/ all interaction
set.seed(2928893)
mod.step.intr <- train(Data_Value ~  YearStart + Age.years. + LocationDesc + YearStart:Age.years. + YearStart:LocationDesc, method = "leapSeq", trControl = control, data.train, trace = FALSE, k = log(nrow(data.train)))
mod.step.intr.RMSE <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"RMSE"]
mod.step.intr.r2 <- mod.step.intr$resample[mod.step.intr$resample[,"nvmax"] == mod.step.intr$bestTune[1,1],"Rsquared"]
#Model Selection - Comparing Models
#Collecting the Errors
rMSPE <- as.matrix(cbind(mod.lm.RMSE, mod.lm.age.RMSE,mod.lm.loc.RMSE,mod.lm.intr.RMSE, mod.step.RMSE, mod.step.age.RMSE,mod.step.loc.RMSE,mod.step.intr.RMSE))
r2 <- as.matrix(cbind(mod.lm.r2, mod.lm.age.r2,mod.lm.loc.r2,mod.lm.intr.r2, mod.step.r2, mod.step.age.r2,mod.step.loc.r2,mod.step.intr.r2))
colnames(rMSPE) <- substr(colnames(rMSPE),1,nchar(colnames(rMSPE)) - 5)
colnames(r2) <- substr(colnames(r2),1,nchar(colnames(r2)) - 3)
mins.MSPE <- apply(rMSPE,1,min)
mins.r2 <- apply(r2,1,max)
#visualizations
boxplot(rMSPE, las = 2, main = "root-MSPE from 10-Fold CV", xlab = "model", ylab = "root-MSPE")
boxplot(rMSPE/mins.MSPE, las = 2, main = "Relative-root-MSPE from 10-Fold CV",xlab = "model", ylab = "Relative root-MSPE")
boxplot(r2, las = 2, main = "R2 value from 10-Fold CV", xlab = "model", ylab = "R2")
## All of the LM models perform decently well
## RESULTS
mod.lm.pred <- predict(mod.lm, newdata = data.test)
mod.lm.age.pred <- predict(mod.lm.age, newdata = data.test)
mod.lm.loc.pred <- predict(mod.lm.loc, newdata = data.test)
mod.lm.intr.pred <- predict(mod.lm.intr, newdata = data.test)
mod.step.pred <- predict(mod.step, newdata = data.test)
mod.step.age.pred <- predict(mod.step.age, newdata = data.test)
mod.step.loc.pred <- predict(mod.step.loc, newdata = data.test)
mod.step.intr.pred <- predict(mod.step.intr, newdata = data.test)
pred <- cbind(mod.lm.pred, mod.lm.age.pred,mod.lm.loc.pred
,mod.lm.intr.pred, mod.step.pred, mod.step.age.pred,mod.step.loc.pred
,mod.step.intr.pred)
calculateMSPE <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- mean((test$Data_Value - mod[,i])^2)
}
result
}
calculateR2 <- function(mod,test){
result <- matrix(nrow = 1, ncol = ncol(mod))
colnames(result) <- colnames(mod)
for(i in 1:ncol(mod)){
result[i] <- cor(mod[,i],test$Data_Value)^2
}
result
}
MSPE.test <- calculateMSPE(pred,data.test)
MSPE.test
# MODEL WITH AGE INTERACTION WITH STATE PERFORMS THE BEST
r2.test <- calculateR2(pred, data.test)
r2.test
#Testing with an abline
plot(data.test$Data_Value, mod.lm.intr.pred)
abline(c(0,1))
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel, k = 2)
summary(mod.lm$finalModel)
knitr::opts_chunk$set(echo = TRUE)
#loading libraries
library(tidyverse)
library(caret)
library(faraway)
library(usmap)
#This section of code loads in the data, deletes columns with extraeous information, and filters the data to Obesity/Weight Status
#loading data
data <- read.csv("nutrition_data.csv", header = TRUE,na.strings=c("","NA"))
min(data$YearEnd)
#Removing Redundant Columns
summary(data)
# Delete Location Desc - LocationAbbr is the same column
# Delete Datasource - All Data comes from the same location
# Delete Topic - Same information As Class
# Delete Data_value_Unit & Data_Value_Type - Unit is all NA and All the data is a value of a type
# Delete Data_Value_Alt - Same information as Data_Value
# Delete Data_Value_FootNote_Symbol & Data_Value_Footnote - Provides information about missing samples
# Delete Total - Adds in no information
# Delete ClassID, TopicID, QUestionID, DataValueTypeID, LocationID, StratificationCategoryID1, StratificationID1
# Delete Low_Confidence_Limit, High_Confidence_Limit, Sample Size - calulated confidence intervals for each sample size
#Other Notes
# Both Confidence Limits, Sample Size
# Age, Education, Gender, Income, Race has a lot of missing Values
# Filter Class to Obesity/Weight Status - Physical Activity and Fruits and Vegetables are irrelevent to the data
# Question TBA
#deleting redundant values
data <-  data %>% select(-c(LocationAbbr,Datasource, Topic,Data_Value_Unit,Data_Value_Type,Data_Value_Alt,Data_Value_Footnote,Data_Value_Footnote_Symbol, Total, ClassID, TopicID, Data_Value_Unit, QuestionID, DataValueTypeID, LocationID, StratificationCategory1, StratificationCategoryId1,Stratification1, StratificationID1))
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel, k = 2)
summary(mod.lm$finalModel)
BIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel)
summary(mod.lm$finalModel)
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel)
summary(mod.lm$finalModel)
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel)
vif(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel)
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel)
vif(mod.lm$finalModel)
summary(mod.lm$finalModel)
AIC(mod.lm$finalModel, mod.lm.age$finalModel, mod.lm.intr$finalModel, mod.lm.loc$finalModel)
vif(mod.lm$finalModel)
summary(mod.lm$finalModel)
